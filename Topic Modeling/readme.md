# Тематическое моделирование

https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5

Cпособ построения модели коллекции текстовых документов, которая определяет, к каким темам относится каждый из документов коллекции.

Тематическая модель (англ. topic model) коллекции текстовых документов определяет, к каким темам относится каждый документ и какие слова (термины) образуют каждую тему.

Алгоритм построения тематической модели получает на входе коллекцию текстовых документов. На выходе для каждого документа выдаётся числовой вектор, составленный из оценок степени принадлежности данного документа каждой из тем. Размерность этого вектора, равная числу тем, может либо задаваться на входе, либо определяться моделью автоматически.

Переход из пространства терминов в пространство найденных тематик помогает разрешать синонимию и полисемию терминов, а также эффективнее решать такие задачи, как тематический поиск, классификация, суммаризация и аннотация коллекций документов и новостных потоков.

Исследователи используют различные тематические модели для анализа текстов, текстовых архивов документов, для анализа изменения тем в наборах документов. Интуитивно понимая, что документ относится к определенной теме, в документах посвященных одной теме можно встретить некоторые слова чаще других

Наибольшее применение в современных приложениях находят подходы, основанные на Байесовских сетях ? вероятностных моделях на ориентированных графах.

Одним из первых был предложен вероятностный латентно-семантический анализ (PLSA), основанный на принципе максимума правдоподобия, как альтернатива классическим методам кластеризации, основанным на вычислении функций расстояния. Вслед за PLSA был предложен метод латентного размещения Дирихле и его многочисленные обобщения.

Вероятностные тематические модели осуществляют ?мягкую? кластеризацию, позволяя документу или термину относиться сразу к нескольким темам с различными вероятностями.

Вероятностные тематические модели основаны на следующих предположениях:

* Порядок документов в коллекции не имеет значения.
* Порядок слов в документе не имеет значения, документ ? мешок слов.
* Слова, встречающиеся часто в большинстве документов, не важны для определения тематики.
* Коллекцию документов можно представить как выборку пар документ-слово.
* Каждая тема описывается неизвестным распределением на множестве слов.
* Каждый документ описывается неизвестным распределением  на множестве тем 



Примеры дополнительных задач: http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5

* ранжировать документы по степени релевантности заданной теме (тематический поиск);
* ранжировать документы по степени тематического сходства с заданным документом или его фрагментом;
* построить иерархический тематический каталог коллекции документов и выработать правила каталогизации новых документов;
* определить, как темы изменялись со временем (предполагается, что для каждого документа известно время его создания);
* определить тематику авторов (предполагается, что для каждого документа известен список второв);
* определить тематику различных сущностей (entities), связанных с документами (например, журналов, конференций, организаций, стран);
* разбить документ на тематически однородные фрагменты.

Типичные приложения:

* анализ коллекций научных статей;
* анализ новостных потоков;
* рубрикация коллекций изображений, видео, музыки;
* аннотация генома и другие задачи биоинформатики;
* коллаборативная фильтрация.

## Вероятностный латентно-семантический анализ
Основные недостатки PLSA:

* Число параметров растёт линейно по числу документов в коллекции, что может приводить к переобучению модели.
* При добавлении нового документа в коллекцию распределение невозможно вычислить по тем же формулам, что и для остальных документов, не перестраивая всю модель заново.

## Латентное размещение Дирихле (LDA)

# Дополнительные ссылки
* http://machinelearning.ru/wiki/index.php?title=%D0%92%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%BD%D1%8B%D0%B5_%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_(%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2)
* Тематические модели для коллекций текстов http://www.machinelearning.ru/wiki/images/8/82/BMMO11_14.pdf
* Вероятностное тематическое моделирование. К.В. Воронцов http://www.machinelearning.ru/wiki/images/2/22/Voron-2013-ptm.pdf
* Тематическое моделирование - К. В. Воронцов https://www.youtube.com/watch?v=H7hlSz4WWhQ

